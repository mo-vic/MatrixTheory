[toc]



# 第二章 向量与矩阵范数

## 第1节 向量的范数

刻画收敛性，以及使用条件数刻画稳定性等都需要用到范数。

在低维的直观几何空间中，有向量长度的概念，将其推广到高维空间中，就有了范数。定义了内积之后，根据内积可以诱导出高维空间中向量长度和夹角的定义，而内积是一个二元函数，有时我们只需要度量向量的长度，这时，只需要一个一元函数，$f(\cdot): V \times V \to R^+$。



==定义1==：设映射$\norm{\cdot}: C^n \to R$满足：

（1）正定性：$\norm{x} \ge 0$，当且仅当$x = 0$时，$\norm{x} = 0$；

（2）齐次性：$\norm{\lambda x} = |\lambda|\norm{x}, \lambda \in C, x \in C^n$；

（3）三角不等式：$\norm{x + y} \le \norm{x} + \norm{y}, \forall_{x, y} \in C^n$，

则称映射$\norm{\cdot}$为$C^n$上向量$x$的范数。



$C^n(C)$定义了范数之后，可以将其转嫁至一般的线性空间$V_n(C)$上。



==向量范数的性质==：

（1）$\norm{0} = 0$；

（2）$x \neq 0$时，$\norm{\frac{1}{\norm{x}}x} = 1$；

（3）对任意的$x \in C^n$，有$\norm{-x} = \norm{x}$；

（4）对任意的$x, y \in C^n$，有$|\norm{x} - \norm{y}| \le \norm{x-y}$。

证：$\norm{x} = \norm{(x - y) + y} \le \norm{x - y} + \norm{y}$，即$\norm{x} - \norm{y} \le \norm{x-y}$；$\norm{y} = \norm{(y - x) + x} \le \norm{y-x}+\norm{x} = \norm{x - y} + \norm{x}$，即$\norm{x} - \norm{y} \ge -\norm{x - y}$，综上$-\norm{x-y} \le \norm{x} - \norm{y} \le \norm{x-y}$，即$|\norm{x} - \norm{y}| \le \norm{x-y}$。



==常见的向量范数==：

设$x = [x_1, x_2, \cdots, x_n]^T \in C^n, y = [y_1, y_2, \cdots, y_n]^T \in C^n$，则：

==1-范数==：$\norm{x}_1 = \sum_{i=1}^n |x_i|$。

（1）正定性显然满足。

（2）$\forall_\lambda \in C$，$\norm{\lambda x}_1 = \sum_{i=1}^n |\lambda x_i| = |\lambda| \sum_{i=1}^n |x_i| = |\lambda|\norm{x}_1$。

（3）$\norm{x + y}_1 = \sum_{i=1}^n |x_i + y_i| \le \sum_{i=1}^n (|x_i| + |y_i|) = \sum_{i=1}^n |x_i| + \sum_{i=1}^n |y_i| = \norm{x}_1 + \norm{y}_1$。



==2-范数==：$\norm{x}_2 = (\sum_{i=1}^n |x_i|^2)^{\frac{1}{2}}$。

（1）正定性显然满足。

（2）$\norm{\lambda x}_2 = (\sum_{i=1}^n |\lambda x_i|^2)^\frac{1}{2} = |\lambda| (\sum_{i=1}^n |x_i|^2)^\frac{1}{2} = |\lambda|\norm{x}_2$。

（3）$\norm{x}_2 = (\sum_{i=1}^n |x_i|^2)^\frac{1}{2}$，等式两边平方，有
$$
\norm{x}_2^2 = \sum_{i=1}^n |x_i|^2 = \left[\begin{array}{cccc}\overline{x_1} &\overline{x_2} &\cdots &\overline{x_n} \end{array}\right]\left[\begin{array}{c}x_1 \\ x_2 \\ \vdots \\v_n\end{array}\right] = x^H x = (x, x)
$$
$C^n$：定义内积$(x, y) = x^H y$，则$(x+y, x+y) = (x+y)^H(x+y) = \norm{x+y}_2^2$，即$x^Hx + y^Hy + x^H y + y^Hx = \norm{x}_2^2 + \norm{y}_2^2 + 2\operatorname{Re}(x^H y) \le \norm{x}_2^2 + \norm{y}_2^2 + 2|x^H y|$，而，$(\norm{x}_2 + \norm{y}_2)^2 = \norm{x}_2^2 + \norm{y}_2^2 + 2\norm{x}_2 \norm{y}_2$。根据内积的性质，$|x^H y| = |(x, y)| \le \sqrt{(x, x)} \cdot \sqrt{(y, y)} = \norm{x}_2 \norm{y}_2$。综上，$\norm{x + y}_2^2 \le (\norm{x}_2+\norm{y}_2)^2$，即$\norm{x+y}_2 \le \norm{x}_2 + \norm{y}_2$。



==无穷范数==：$\norm{x}_\infty = \max_{1 \le i \le n} |x_i|$。

（1）正定性显然满足。

（2）齐次性参考1-范数的证明。

（3）$\norm{x + y}_\infty = \max_{1 \le i \le n} |x_i + y_i| \le \max_{1 \le i \le n} (|x_i| + |y_i|) \le \max_{1 \le i \le n} |x_i| + \max_{1 \le i \le n} |y_i| = \norm{x}_\infty + \norm{y}_\infty$。



==引理（Young不等式）==：若$u, v$是非负实数，$p, q$是正实数，且==满足条件$p, q > 1$和$\frac{1}{p} + \frac{1}{q} = 1$==（称$p, q$为共轭指数），则有不等式$uv \le \frac{1}{p}u^p + \frac{1}{q}v^q$。

（目标迁移的思想：证明不等式的问题，可以构造函数，求函数的极值点）

证：

（1）若$uv = 0$，不等式显然成立；

（2）若$uv \neq 0$，要证$\frac{1}{p}u^p + \frac{1}{q}v^q - uv \ge 0$。

构造函数$f(v) = \frac{1}{p}u^p + \frac{1}{q}v^q - uv$（把$v$看做自变量，$u$看做常数），则$f(v)$是一元函数。现求函数的驻点：

$f^\prime(v) = v^{q-1} - u$，令$f^\prime(v) = 0$，即$v^{q-1} - u = 0$，解得$v_0 = u^{\frac{1}{q-1}}$。

$f^{\prime\prime}(v) = (q-1)v^{q-2}$，因为$q > 1$，所以$f^{\prime\prime}(v) = (q-1)v^{q-2} > 0$，从而$f(v_0)$为极小值，有$f(v) \ge f(v_0)$，即$\frac{1}{p}u^p + \frac{1}{q}v^q - uv \ge \frac{1}{p}u^p + \frac{1}{q}v_0^q - uv_0 = \frac{1}{p}u^p + \frac{1}{q}u^\frac{q}{q-1} - u^\frac{q}{q-1}$。

由$\frac{1}{p} + \frac{1}{q} = 1 \Longrightarrow \frac{1}{p} = 1 - \frac{1}{q} = \frac{q-1}{q} \Longrightarrow \frac{q}{q-1} = p$，从而：$\frac{1}{p}u^p + \frac{1}{q}u^\frac{q}{q-1} - u^\frac{q}{q-1} = \frac{1}{p}u^p + \frac{1}{q}u^p - u^p = (\frac{1}{p}+\frac{1}{q} - 1)u^p = 0$，所以$\frac{1}{p}u^p + \frac{1}{q}v^q - uv \ge 0$，即$uv \le \frac{1}{p}u^p + \frac{1}{q}v^q$。



==Hölder不等式==：若$p, q > 1$，且$\frac{1}{p} + \frac{1}{q} = 1$，则对$C^n$任意向量$x = [x_1, x_2, \cdots, x_n]^T, y = [y_1, y_2, \cdots, y_n]^T$都有$\sum_{i=1}^n |x_i| \cdot |y_i| \le (\sum_{i=1}^n |x_i|^p)^\frac{1}{p}(\sum_{i=1}^n |y_i|^q)^\frac{1}{q}$。

证：$u = \frac{|x_i|}{\norm{x}_p}, v = \frac{|y_i|}{\norm{y}_q}$，则$\frac{|x_i|\cdot|y_i|}{\norm{x}_p \cdot \norm{y}_q} \le \frac{1}{p}\frac{|x_i|^p}{\norm{x}_p^p} + \frac{1}{q}\frac{|y_i|^q}{\norm{y}_q^q}, 1 \le i \le n$，$\sum_{i=1}^n \frac{|x_i|\cdot|y_i|}{\norm{x}_p \cdot \norm{y}_q} \le \frac{1}{p\norm{x}_p^p}\sum_{i=1}^n |x_i|^p + \frac{1}{q\norm{y}_q^q}\sum_{i=1}^n |y_i|^q = \frac{1}{p} + \frac{1}{q} = 1$，因此$\frac{1}{\norm{x}_p \cdot \norm{y}_q}\sum_{i=1}^n |x_i| \cdot |y_i| \le 1$，即$\sum_{i=1}^n |x_i| \cdot |y_i| \le \norm{x}_p \cdot \norm{y}_q = (\sum_{i=1}^n |x_i|^p)^\frac{1}{p}(\sum_{i=1}^n |y_i|^q)^\frac{1}{q}$。



特别地：当$p = q = 2$时，设$\alpha = [|x_1|, |x_2|, \cdots, |x_n|]^T, \beta = [|y_1|, |y_2|, \cdots, |y_n|]$，则$\sum_{i=1}^n |x_i| \cdot |y_i| = |\alpha^T\beta| = |(\alpha, \beta)| \le \sqrt{(\alpha, \alpha)} \cdot \sqrt{(\beta, \beta)} = (\sum_{i=1}^n |x_i|^2)^\frac{1}{2} \cdot (\sum_{i=1}^n |y_i|^2)^\frac{1}{2} = \norm{x}_2 \cdot \norm{y}_2$。



==p-范数==（Hölder范数）：$\norm{x}_p = (\sum_{i=1}^n |x_i|^p)^\frac{1}{p}, 1 \le p < +\infty$。

（1）正定性显然满足。

（2）齐次性参考2-范数的证明。

（3）

证：设$p, q > 1$，且$\frac{1}{p} + \frac{1}{q} = 1$，
$$
\sum_{i=1}^n (|x_i|+|y_i|)^p = \sum_{i=1}^n (|x_i|+|y_i|)(|x_i|+|y_i|)^{p-1} \\
= \sum_{i=1}^n |x_i|(|x_i|+|y_i|)^{p-1}+\sum_{i=1}^n |y_i|(|x_i|+|y_i|)^{p-1} \\
\le (\sum_{i=1}^n |x_i|^p)^\frac{1}{p}[\sum_{i=1}^n (|x_i|+|y_i|)^{(p-1)q}]^\frac{1}{q} + (\sum_{i=1}^n |y_i|^p)^\frac{1}{p}[\sum_{i=1}^n (|x_i|+|y_i|)^{(p-1)q}]^\frac{1}{q} \\
= [(\sum_{i=1}^n |x_i|^p)^\frac{1}{p} + (\sum_{i=1}^n |y_i|^p)^\frac{1}{p}] \cdot [\sum_{i=1}^n (|x_i|+|y_i|)^{(p-1)q}]^\frac{1}{q}
$$
由$\frac{1}{p} + \frac{1}{q} = 1 \Longrightarrow \frac{1}{q} = 1 - \frac{1}{p} = \frac{p-1}{p}$，即$(p-1)q = p$，则$\sum_{i=1}^n (|x_i|+|y_i|)^p \le  [(\sum_{i=1}^n |x_i|^p)^\frac{1}{p} + (\sum_{i=1}^n |y_i|^p)^\frac{1}{p}] \cdot [\sum_{i=1}^n (|x_i|+|y_i|)^p]^\frac{1}{q}$，不等式两边同除$[\sum_{i=1}^n (|x_i|+|y_i|)^p]^\frac{1}{q}$，得$[\sum_{i=1}^n (|x_i| + |y_i|)]^{1-\frac{1}{q}} \le (\sum_{i=1}^n |x_i|^p)^\frac{1}{p} + (\sum_{i=1}^n |y_i|^p)^\frac{1}{p}$，即$[\sum_{i=1}^n (|x_i| + |y_i|)]^{\frac{1}{p}} \le (\sum_{i=1}^n |x_i|^p)^\frac{1}{p} + (\sum_{i=1}^n |y_i|^p)^\frac{1}{p}$，再由$(\sum_{i=1}^n |x_i + y_i|^p)^\frac{1}{p} \le [\sum_{i=1}^n (|x_i| + |y_i|)^p]^\frac{1}{p}$，得$\norm{x+y}_p \le \norm{x}_p + \norm{y}_p$。

当$p = 1$时即为1-范数。



当$0 < 0 < 1$时，$\norm{x}_p$不是范数，这里举个简单的例子：

设$p = \frac{1}{2}$，$x = [1, 0]^T, y = [0, 1]^T \longrightarrow x + y = [1, 1]^T$，$\norm{x}_{\frac{1}{2}} = (\sum_{1}^n |x_i|^\frac{1}{2})^2 = 1, \norm{y}_{\frac{1}{2}} = (\sum_{1}^n |y_i|^\frac{1}{2})^2 = 1, \norm{x+y}_{\frac{1}{2}} = (\sum_{1}^n |x_i+y_i|^\frac{1}{2})^2 = 4$，$\norm{x+y}_\frac{1}{2} = 4 \not \le 2 = \norm{x}_\frac{1}{2} + \norm{y}_\frac{1}{2}$。



==当$p \to \infty$时$\norm{x}_p$的极限==：

令$|x_0| = \max_{i=1}^n |x_i| = \norm{x}_\infty$，则

$\norm{x}_\infty = |x_0| = (|x_0|^p)^\frac{1}{p} \le \norm{x}_p = (\sum_{i=1}^n |x_i|^p)^\frac{1}{p} \le (\sum_{i=1}^n |x_0|^p)^\frac{1}{p} = (n |x_0|^p)^\frac{1}{p} = n^\frac{1}{p} |x_0| = n^\frac{1}{p} \norm{x}_\infty$，从而$\lim_{p \to \infty} \norm{x}_p = \norm{x}_\infty$。



==诱导向量范数==（由已知范数生成新范数）：

==诱导方式一==：
$$
C^m: \norm{\cdot}_\alpha (已知范数) &\longrightarrow &C^n: \norm{\cdot}_\beta (未知范数)  & \overset{f}{\longrightarrow} &R^+ \\
\downarrow & &\downarrow & \\
y = Ax &\overset{取定A \in C_n^{m \times n}}{\longleftarrow} & \forall_x & \overset{f}{\longrightarrow} &f(x) \in R^+
$$
因此，可以将未知范数$\norm{\cdot}_\beta$定义为$\norm{\cdot}_\beta = \norm{y}_\alpha = \norm{Ax}_\alpha$。

==定理1==：设$\norm{\cdot}$是$c^m$上的范数，$A \in C_n^{m \times n}$（列满秩矩阵），则$\norm{A\cdot}$是$C^n$上的范数。

证：

（1）$\norm{x}_\beta \triangleq \norm{Ax}_\alpha \ge 0$，且$\norm{x}_\beta = 0 \Longleftrightarrow \norm{Ax}_\alpha = 0 \Longleftrightarrow Ax = 0$，由于$A$是列满秩矩阵，所以方程组$Ax = 0$只有零解$x = 0$，即$\norm{x}_\beta = 0 \Longleftrightarrow x = 0$。

（2）$\norm{\lambda x}_\beta = \norm{A \lambda x}_\alpha = \norm{\lambda Ax}_\alpha = |\lambda|\norm{Ax}_\alpha = |\lambda|\norm{x}_\beta$。

（3）$\norm{x + y}_\beta = \norm{A(x + y)}_\alpha = \norm{Ax + Ay}_\alpha \le \norm{Ax}_\alpha + \norm{Ay}_\alpha = \norm{x}_\beta + \norm{y}_\beta$。



举一个特例：

设$C^n$上的范数为$f(x) \to R^+:\norm{x}_A = \sqrt{x^H A x}$，其中$A^H = A$且正定，则$A = P^HP$（$P$为可逆矩阵）。从而$\norm{x}_A = \sqrt{x^H A x} = \sqrt{x^H P^H P x} = \sqrt{(Px)^H (Px)} = \norm{Px}_2$（椭圆范数），这里$P \in C_n^{n \times n}$，$\norm{\cdot}_\alpha = \norm{\cdot}_2$。



也可以按照定义证明$f(x) \to R^+:\norm{x}_A = \sqrt{x^H A x}$是$C^n$上的范数。

证：

（1）正定性：由于矩阵$A$是Hermite正定矩阵，正定性显然成立；

（2）齐次性：容易证明，略。

（3）三角不等式：

要证：$\norm{x+y}_A \le \norm{x}_A + \norm{y}_A$，等价于证明$\norm{x+y}_A^2 \le (\norm{x}_A + \norm{y}_A)^2$。不等式左右两边分别展开：$(x+y)^H A (x + y) = (x^H + y^H) A (x+y) = x^H A x + y^H A x + x^H A y + y^H A y = \norm{x}_A^2 + \norm{y}_A^2 + 2\operatorname{Re}(x^H A y) \le \norm{x}_A^2 + \norm{y}_A^2 + 2 |x^H A y|$，$(\norm{x}_A + \norm{y}_A)^2 = \norm{x}_A^2 + \norm{y}_A^2 + 2\norm{x}_A \norm{y}_A$，而$x^H A y = (x, y), \norm{x}_A = \sqrt{x^H A x} = \norm{x}_, \norm{y}_A = \sqrt{y^H A y} = \norm{y}$，根据向量内积的性质，$|(x, y)| \le \norm{x} \cdot \norm{y}$，即$|x^H A y| \le \norm{x}_A \cdot \norm{y}_A$，证毕！





==诱导方式二==：

设$\epsilon_1, \epsilon_2, \cdots \epsilon_n$为线性空间$V_n(P)$的一组基，$x=[\epsilon_1, \epsilon_2, \cdots, \epsilon_n]\tilde{x}, \tilde{x} = [x_1, x_2, \cdots, x_n]^T$，$\norm{x} \triangleq \norm{\tilde{x}}$。（给定基之后，坐标与向量一一对应，所以可以用坐标的范数来刻画一般的线性空间中向量的范数）





==范数与刻画收敛性、稳定性等的关系==：

范数多种多样，使用不同的范数对收敛性、稳定性等进行刻画会不会产生不同的结果？



==定义2==：设在$V_n(P)$上定义了$\norm{x}_a, \norm{x}_b$两种向量范数，若存在常数$C_1 > 0, C_2 > 0$，使得$C_1 \norm{x}_a \le \norm{x}_b \le C_2 \norm{x}_a$，则称$\norm{x}_a$与$\norm{x}_b$等价。



==定理2==：$V_n(P)$上任意两个向量的范数均等价。

证：要证$C_1 \norm{x}_a \le \norm{x}_b \le C_2 \norm{x}_a$，构造函数$f(x) = \frac{\norm{x}_b}{\norm{x}_a}$，即证$C_1 \le f(x) = \frac{\norm{x}_b}{\norm{x}_a} \le C_2$，即证函数$f(x)$有界。证明需要用到拓扑学的知识。这里只要求记住结论。



==向量序列的收敛性==（线性控制论常用）：

==定义3==：设$x^{(k)} = [x_1^{(k)}, x_2^{(k)}, \cdots, x_n^{(k)}]^T \in C^n$，如果$\lim_{k \to \infty}x_i^{(k)} = a_i, (i=1,2,\cdots,n)$，则称向量序列$x^{(k)}$收敛于$a = [a_1, a_2, \cdots, a_n]^T$。
$$
k = 1 &x^{(1)} &= &[&x_1^{(1)}, &x_2^{(1)}, &\cdots, &x_n^{(1)} &]^T \\
k = 2 &x^{(2)} &= &[&x_1^{(2)}, &x_2^{(2)}, &\cdots, &x_n^{(2)} &]^T \\
\cdots &\cdots & & &\cdots &\cdots &\cdots &\cdots \\
k &x^{(k)} &= &[&x_1^{(k)}, &x_2^{(k)}, &\cdots, &x_n^{(k)} &]^T \\
\downarrow &\downarrow & & &\downarrow &\downarrow &\cdots &\downarrow \\
\infty &a & &[ &a_1 &a_2, &\cdots &a_n &]^T
$$


通过研究$n$个数列的极限来研究向量序列的收敛性，当$n$非常大时，如何降低研究$n$个数列极限的难度？

答：通过归一化，$\lim_{k \to \infty}\norm{x^{(k)} - a} = 0$，即转化为研究一个数列极限的问题。



==定理3==：设$\norm{\cdot}$是$C^n$上的任意向量范数，则$\lim_{k \to \infty}x^{(k)} = a \Longleftrightarrow \lim_{k \to \infty}\norm{x^{(k)} - a} = 0$。

证：
$$
\lim_{k \to \infty} x^{(k)} = a \Longleftrightarrow \lim_{k \to \infty}x_i^{(k)} = a_i \Longleftrightarrow \lim_{k \to \infty}\max_{1 \le i \le n}\{|x_i^{(k)} - a_i|\} = 0 \\
\Longleftrightarrow \lim_{k \to \infty}\norm{x^{(k)} - a}_\infty = 0
$$
由于$V_n(P)$上任意两个向量的范数均等价，则存在$m, M > 0$，使得$m\norm{x^{(k)} - a}_\infty \le \norm{x^{(k)}-a} \le M\norm{x^{(k)} - a}_\infty$，根据夹逼准则，有$\lim_{k \to \infty}\norm{x^{(k)} - a} = \lim_{k \to \infty}\norm{x^{(k)} - a}_\infty = 0$。





## 第2节 矩阵的范数

设$A = (a_{ij})_{m \times n} = [\alpha_1, \alpha_2, \cdots, \alpha_n]$，将矩阵的每一列依次叠加，构造向量$l^A = \left[\begin{array}{c}\alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_n\end{array}\right] \in C^{mn}$，记为$\operatorname{vec}(A)$，称为矩阵$A$的向量化符号。由于矩阵的加法和矩阵的数乘分别与向量的加法和向量的数乘相同（即对应分量相加、数与各分量相乘），因而在线性空间中，矩阵和向量没有本质的区别，因此向量的范数可以迁移到矩阵上面。

==定义1==：设$A \in P^{m \times n}$，若映射$\norm{\cdot}: P^{m \times n} \to R$，满足

（1）正定性：$\norm{A} \ge 0$，当且仅当$A = 0$时，$\norm{A} = 0$；

（2）齐次性：$\norm{\lambda A} = |\lambda|\norm{A}, \forall_\lambda \in P, \forall_A \in P^{m \times n}$；

（3）三角不等式：$\norm{A+B} \le \norm{A} + \norm{B}, \forall_{A, B} \in P^{m \times n}$，

则称映射$\norm{\cdot}$为$P^{m \times n}$上的矩阵范数。



==常见的矩阵范数==：

设$A \in P^{m \times n}$：

$\norm{A}_{m_1} = \norm{l^A}_1 = \sum_{j=1}^n\sum_{i=1}^m |a_{ij}|$——$m_1$范数；

$\norm{A}_{m_2} = \norm{l^A}_2 = (\sum_{j=1}^n\sum_{i=1}^m |a_{ij}|^2)^\frac{1}{2}$——$m_2$范数，也记为$\norm{A}_F$（为了纪念Frobenius）；

$\norm{A}_{m_\infty} = \norm{l^A}_\infty = \max_{i,j}|a_{ij}|$——$m_\infty$范数。

矩阵的p-范数并不常用。



==矩阵范数的相容性==：

从两个已知矩阵$A, B$的误差大小，估计矩阵$AB$的误差大小。

==定义2==：设$\norm{\cdot}_a: P^{m \times l} \to R, \norm{\cdot}_b: P^{l \times n} \to R, \norm{\cdot}_c: P^{m \times n} \to R$是矩阵范数，如果$\norm{AB}_c \le \norm{A}_a \cdot \norm{B}_b$，则称矩阵范数$\norm{\cdot}_a, \norm{\cdot}_b, \norm{\cdot}_c$相容。



如果$\norm{\cdot}_a = \norm{\cdot}_b = \norm{\cdot}_c = \norm{\cdot}$，即同一范数，如果$\norm{AB}_c \le \norm{A}_a \cdot \norm{B}_b$，则称$\norm{\cdot}$是自相容矩阵范数。



==常见矩阵范数的相容性==：

（1）$\norm{AB}_{m_\infty} \not \le \norm{A}_{m_\infty} \cdot \norm{B}_{m_\infty}$

例：设$A = \left[\begin{array}{cc}1 &1 \\ 0 &0\end{array}\right], B = \left[\begin{array}{cc}1 &0 \\ 1 &0\end{array}\right], AB = \left[\begin{array}{cc}2 &0 \\ 0 &0\end{array}\right]$，$\norm{AB}_{m_\infty} = 2, \norm{A}_{m_\infty} = 1, \norm{B}_{m_\infty} = 1$。

（2）$\norm{AB}_{m_1} \le \norm{A}_{m_1} \cdot \norm{B}_{m_1}$。

证：设$A \in P^{m \times l}, B \in P^{l \times n}$，$AB = C = (c_{ij}) \in P^{m \times n}$，其中$c_{ij} = \sum_{k=1}^l a_{ik} b_{kj}$。
$$
\norm{AB}_{m_1} = \norm{C}_{m_1} = \sum_{j=1}^n \sum_{i=1}^m |c_{ij}| = \sum_{j=1}^n \sum_{i=1}^m |\sum_{k=1}^l a_{ik} b_{kj}| \\
\le \sum_{j=1}^n \sum_{i=1}^m \sum_{k=1}^l |a_{ik}| \cdot |b_{kj}| \le \sum_{j=1}^n \sum_{i=1}^m \sum_{k=1}^l |a_{ik}| \cdot \sum_{k=1}^l |b_{kj}| \\
= \sum_{j=1}^n \sum_{k=1}^l |b_{kj}| \sum_{i=1}^m \sum_{k=1}^l |a_{ik}| = (\sum_{i=1}^m \sum_{k=1}^l |a_{ik}|) \cdot (\sum_{j=1}^n \sum_{k=1}^l |b_{kj}|) \\
= \norm{A}_{m_1} \cdot \norm{B}_{m_1}
$$
（3）$\norm{AB}_{m_2} \le \norm{A}_{m_2} \cdot \norm{B}_{m_2}$。

证：设$A \in P^{m \times l}, B \in P^{l \times n}$，$AB = C = (c_{ij}) \in P^{m \times n}$，其中$c_{ij} = \sum_{k=1}^l a_{ik} b_{kj}$。
$$
\norm{AB}_{m_2} = \norm{C}_{m_2} = (\sum_{j=1}^n \sum_{i=1}^m |c_{ij}|^2)^\frac{1}{2} = (\sum_{j=1}^n \sum_{i=1}^m |\sum_{k=1}^l a_{ik}b_{kj}|^2)^\frac{1}{2} \\
\le [\sum_{j=1}^n \sum_{i=1}^m (\sum_{k=1}^l |a_{ik}| \cdot |b_{kj}|)^2]^\frac{1}{2} \\
\le [\sum_{j=1}^n \sum_{i=1}^m (\sum_{k=1}^l |a_{ik}|^2) \cdot (\sum_{k=1}^l |b_{kj}|^2)]^\frac{1}{2} \\
= \{\sum_{j=1}^n (\sum_{k=1}^l |b_{kj}|^2) \cdot [\sum_{i=1}^m(\sum_{k=1}^l|a_{ik}|^2)]\}^\frac{1}{2} \\
= (\sum_{i=1}^m\sum_{k=1}^l |a_{ik}|^2)^\frac{1}{2} \cdot (\sum_{k=1}^l\sum_{j=1}^n |b_{kj}|^2)^\frac{1}{2} \\
= \norm{A}_{m_2} + \norm{B}_{m_2}
$$

其中，$[\sum_{j=1}^n \sum_{i=1}^m (\sum_{k=1}^l |a_{ik}| \cdot |b_{kj}|)^2]^\frac{1}{2} \le [\sum_{j=1}^n \sum_{i=1}^m (\sum_{k=1}^l |a_{ik}|^2) \cdot (\sum_{k=1}^l |b_{kj}|^2)]^\frac{1}{2}$使用了柯西——许瓦茨不等式。





==$m_2$矩阵范数的性质==（$m_2$矩阵范数比$m_1$矩阵范数常用）：

设$A = (a_{ij})_{m \times n} = [\alpha_1, \alpha_2, \cdots, \alpha_n] \in P^{m \times n}, \alpha_j = [a_{1j}, a_{2j}, \cdots, a_{mj}]^T$，则

（1）$\norm{A}_{m_2}^2 = \norm{A}_F^2 = \tr(A^HA) = \sum_{i=1}^n \lambda_i (A^HA)$。

证：
$$
A^HA = 
\left[\begin{array}{c}
\alpha_1^H \\
\alpha_2^H \\
\vdots \\
\alpha_n^H
\end{array}\right]

\left[\begin{array}{cccc}
\alpha_1 &\alpha_2 &\cdots &\alpha_n
\end{array}\right]
= 
\left[\begin{array}{cccc}
\alpha_1^H\alpha_1 &\alpha_1^H\alpha_2 &\cdots &\alpha_1^H\alpha_n \\
\alpha_2^H\alpha_1 &\alpha_2^H\alpha_2 &\cdots &\alpha_2^H\alpha_n \\
\vdots &\cdots &\ddots &\vdots \\
\alpha_n^H\alpha_1 &\alpha_n^H\alpha_2 &\cdots &\alpha_n^H\alpha_n \\
\end{array}\right]
$$
从而$\norm{A}_{m_2}^2 = \norm{A}_F^2 = \sum_{j=1}^n \sum_{i=1}^m |a_{ij}|^2 = \sum_{j=1}^n \norm{\alpha_j}_2^2 = \sum_{j=1}^n \alpha_j^H \alpha_j = \tr(A^HA) = \sum_{i=1}^n \lambda_i (A^HA)$。



（2）若$A^H = A$，则$A^H = A \Longrightarrow \norm{A}_{m_2}^2 = \sum_{i=1}^n \lambda_i(A^HA) = \sum_{i=1}^n \lambda_i(A^2) = \sum_{i=1}^n \lambda_i^2(A) \Longrightarrow \norm{A}_{m_2} = [\sum_{i=1}^n \lambda_i^2(A)]^\frac{1}{2}$。



（3）若$A^H = A, B^H = B, AB = BA$，则$\sum_{i=1}^n \lambda_i^2(AB) \le [\sum_{i=1}^n \lambda_i^2(A)] \cdot [\sum_{i=1}^n \lambda_i^2(B)]$。

证：$A^H = A, B^H = B, AB = BA \Longrightarrow (AB)^H = B^HA^H = BA = AB$，所以$AB$是Hermite矩阵。从而$\norm{AB}_{m_2}^2 = \sum_{i=1}^n \lambda_i^2(AB), \norm{A}_{m_2}^2 = \sum_{i=1}^n \lambda_i^2(A), \norm{B}_{m_2}^2 = \sum_{i=1}^n \lambda_i^2(B)$，由矩阵的$m_2$范数是自相容的，有$\norm{AB}_{m_2} \le \norm{A}_{m_2} \cdot \norm{B}_{m_2} \Longrightarrow \norm{AB}_{m_2}^2 \le \norm{A}_{m_2}^2 \cdot \norm{B}_{m_2}^2 \Longrightarrow \sum_{i=1}^n \lambda_i^2(AB) \le [\sum_{i=1}^n \lambda_i^2(A)] \cdot [\sum_{i=1}^n \lambda_i^2(B)]$。



（4）设$A \in P^{m \times n}$，$U \in P^{m \times m}, V \in P^{n \times n}$是任意酉矩阵，则有$\norm{UAV}_{m_2} = \norm{UA}_{m_2} = \norm{AV}_{m_2} = \norm{A}_{m_2}$，称为矩阵的$m_2$范数的酉不变性。

==意义==：当矩阵$A$阶数较大时，矩阵的$m_2$范数不好计算，可以利用$U, V$对$A$进行行、列变换，使得矩阵出现多个零元素。

证：$V^H V = E \Longrightarrow V^{-1} = V^H$，从而矩阵$V^H A^HA V$相似于矩阵$A^HA$，从而$\norm{A}_{m_2}^2 = \tr(A^H A) = \tr(V^H A^H A V) = \tr(V^H A^H U^H U A V) = \tr[(UAV)^H (UAV)] = \norm{UAV}_{m_2}^2$。





## 第3节 算子范数

设有一信号$x$，现对其做一线性变换得到$y = Ax$；若信号$x$出现干扰，使得$x^\prime = x + \Delta x$，从而做线性变换后$y^\prime = y + \Delta y = Ax^\prime = A(x + \Delta x) = Ax + A\Delta x$，即$\Delta y = A\Delta x$，现需要估计误差项$\Delta y$的大小。

使用向量范数对误差大小进行刻画，则$\norm{\Delta y}_\alpha = \norm{A\Delta x}_\alpha$，若存在$\norm{A}_m$使得$\norm{\Delta y}_\alpha = \norm{A\Delta x}_\alpha \le \norm{A}_{m} \cdot \norm{\Delta x}_\alpha$，则可以使用$\norm{A}_{m} \cdot \norm{\Delta x}_\alpha$来估计误差大小。

在数值分析中：

$\norm{\Delta y}_\alpha \le \norm{A}_{m} \cdot \norm{\Delta x}_\alpha$称为绝对误差估计，$\frac{\norm{\Delta y}_\alpha}{\norm{\Delta x}_\alpha} \le \norm{A}_{m}$称为相对误差估计。

由此引出矩阵范数与向量范数的相容性。



### 一、矩阵范数与向量范数的相容性

==定义1==：设$\norm{\cdot}_a$是$P^n$上的向量范数，$\norm{\cdot}_m$是$P^{n \times n}$上的矩阵范数，$\forall_{x} \in P^n, \forall_A \in P^{n \times n}$，若$\norm{Ax}_a \le \norm{A}_m \cdot \norm{x}_a$，则称$\norm{\cdot}_m$为与向量范数$\norm{\cdot}_a$相容的矩阵范数。



例1：设$x \in P^n, A \in P^{n \times n}$，则$\norm{A}_{m_1} = \sum_{j=1}^n\sum_{i=1}^n |a_{ij}|$是与$\norm{x}_1$相容的矩阵范数。

例2：设$x \in P^n, A \in P^{n \times n}$，则$\norm{A}_{m_2} = (\sum_{j=1}^n\sum_{i=1}^n |a_{ij}|^2)^\frac{1}{2}$是与$\norm{x}_2$相容的矩阵范数。



与向量范数$\norm{\cdot}_a$相容的矩阵范数可能有多个，为了保证误差估计的准确性，应选择其中一个最小的范数。



### 二、算子范数（由向量范数诱导的矩阵范数）

$$
P^n: \norm{\cdot}_\alpha (已知范数) &\overset{诱导}\longrightarrow &P^{n \times n}: \norm{\cdot}_\beta (未知范数)  & \overset{f}{\longrightarrow} &R^+ \\
\downarrow & &\downarrow & \\
\forall_x \in P^n &\overset{\norm{A}_\beta = \frac{\norm{Ax}_\alpha}{\norm{x}_\alpha}}{\longrightarrow} & \forall_A & \overset{f(A) \triangleq \max_{x \neq 0}\frac{\norm{Ax}_\alpha}{\norm{x}_\alpha}}{\longrightarrow} &f(A) \in R^+
$$

==定理1==：设$\norm{x}_a$是$P^n$上的向量范数，$A = [\alpha_1, \alpha_2, \cdots, \alpha_n]^T \in P^{n \times n}$，则$\norm{A}_a = \max_{x \neq 0}\frac{\norm{Ax}_a}{\norm{x}_a}$是矩阵范数。

证：

（1）$\norm{A}_a = \max_{x \neq 0}\frac{\norm{Ax}_a}{\norm{x}_a} \ge 0$，

一方面：$A = 0 \Longrightarrow \norm{A}_a = 0$，

另一方面：$\norm{A}_a = 0 \Longleftrightarrow \max_{x \neq 0}\frac{\norm{Ax}_a}{\norm{x}_a} = 0 \Longleftrightarrow \forall_x, \norm{Ax}_a = 0$（最大值都等于零了，其他任何取值肯定都等于零了），由$x$的任意性，设$x = e_j = [0, 0, \cdots, 1_{[j]}, 0, \cdots, 0]^T$，则$\forall_x, \norm{Ax}_a = 0 \Longrightarrow \norm{Ae_j}_a = 0 \Longleftrightarrow \norm{\alpha_j} = 0 \Longleftrightarrow \forall_j, \alpha_j = 0 \Longleftrightarrow A = 0$。

（2）$\norm{\lambda A}_a = \max_{x \neq 0}\frac{\norm{\lambda Ax}_a}{\norm{x}_a} = \max_{x \neq 0}\frac{|\lambda| \cdot \norm{Ax}_a}{\norm{x}_a} = |\lambda| \cdot \max_{x \neq 0}\frac{\norm{Ax}_a}{\norm{x}_a} = |\lambda| \cdot \norm{A}_a$。

（3）$\norm{A+B} = \max_{x \neq 0}\frac{\norm{(A+B)x}_a}{\norm{x}_a} = \max_{x \neq 0}\frac{\norm{Ax + Bx}_a}{\norm{x}_a} \le \max_{x \neq 0}\frac{\norm{Ax}_a + \norm{Bx}_a}{\norm{x}_a} \le \max_{x \neq 0}\frac{\norm{Ax}_a}{\norm{x}_a} + \max_{x \neq 0}\frac{\norm{Bx}_a}{\norm{x}_a} = \norm{A}_a + \norm{B}_a$。



==推论1==：设$\norm{x}_a$是$P^n$上的向量范数，$A = [\alpha_1, \alpha_2, \cdots, \alpha_n]^T \in P^{n \times n}$，则$\norm{A}_a = \max_{x \neq 0}\frac{\norm{Ax}_a}{\norm{x}_a}$是与向量范数$\norm{x}_a$相容的矩阵范数。

证：$\norm{A}_a = \max_{x \neq 0}\frac{\norm{Ax}_a}{\norm{x}_a} \ge \frac{\norm{Ax}_a}{\norm{x}_a} \Longrightarrow \norm{Ax}_a \le \norm{A}_a \cdot \norm{x}_a$。





==推论2==（算子范数是自相容矩阵范数）：设$\norm{x}_a$是$P^n$上的向量范数，$A, B \in P^{n \times n}$，$\norm{A}_a$是从属于$\norm{x}_a$的算子范数，则它是相容的矩阵范数，即$\norm{AB}_a \le \norm{A}_a \cdot \norm{B}_a$。

证：$\norm{AB}_a = \max_{x \neq 0}\frac{\norm{ABx}_a}{\norm{x}_a} = \max_{x \neq 0}\frac{\norm{A(Bx)}_a}{\norm{x}_a} \le \max_{x \neq 0}\frac{\norm{A}_a \cdot \norm{Bx}_a}{\norm{x}_a} = \norm{A}_a \cdot \max_{x \neq 0}\frac{\norm{Bx}_a}{\norm{x}_a} = \norm{A}_a \cdot \norm{B}_a$。



==算子范数的特性==：

（1）它是所有与向量范数$\norm{x}_a$相容的矩阵范数中最小的。

证：$\forall_{\norm{\cdot}_m}, \norm{Ax}_a \le \norm{A}_m \cdot \norm{x}_a, \forall_{x \neq 0} \in P^n \Longrightarrow \frac{\norm{Ax}_a}{\norm{x}_a} \le \norm{A}_m, \forall_{x \neq 0} \in P^n \Longrightarrow \norm{A}_a = \max_{x \neq 0}\frac{\norm{Ax}_a}{\norm{x}_a} \le \norm{A}_m$。



（2）它的另一种表达方式：

$\norm{A}_a = \max_{x \neq 0}\frac{\norm{Ax}_a}{\norm{x}_a} \Longrightarrow u = \frac{x}{\norm{x}_a} \Longrightarrow x = \norm{x}_a  \cdot u = \lambda u$，从而$\norm{A}_a = \max_{x \neq 0}\frac{\norm{Ax}_a}{\norm{x}_a} = \max_{\norm{u}_a = 1}\frac{\norm{A \lambda u}_a}{\norm{\lambda u}_a} = \max_{\norm{u}_a = 1}\frac{|\lambda| \cdot \norm{Au}_a}{|\lambda| \cdot \norm{u}_a} = \max_{\norm{u}_a = 1} \norm{Au}_a$。



（3）$\norm{\cdot}_a$是算子范数$\Longrightarrow$$\norm{E}_a = 1$，$\therefore \norm{E}_a \neq 1 \Longrightarrow \norm{\cdot}_a$不是算子范数。



==补充==：

 已知矩阵的$\norm{\cdot}_{m_\infty}$范数不是自相容的矩阵范数，即$\norm{AB}_{m_{\infty}} \not \le \norm{A}_{m_\infty} \cdot \norm{B}_{m_\infty}$。但是：

（1）若$A \in P^{n \times n}$，令$\norm{A}_a = n \cdot \max_{i,j}|a_{ij}| = n \cdot \norm{A}_{m_\infty}$，则$\norm{AB}_a \le \norm{A}_a \cdot \norm{B}_a$；

（2）若$A \in P^{m \times n}$，令$\norm{A}_b = \max\{m, n\} \cdot \max_{i,j}|a_{ij}| = \max\{m, n\} \cdot \norm{A}_{m_\infty}$，则$\norm{AB}_b \le \norm{A}_b \cdot \norm{B}_b$。



### 三、矩阵范数诱导向量范数

$$
P^{n \times n}: \norm{\cdot}_m (已知范数) &\overset{诱导}\longrightarrow &P^n: \norm{\cdot}_a (未知范数)  & \overset{f}{\longrightarrow} &R^+ \\
\  & &\downarrow 取定\alpha = \left[\begin{array}{c}a_1 \\ a_2  \\ \vdots \\ a_n\end{array}\right] & \\
\  &  & \forall_x \in P^n & \overset{f(x) \triangleq \norm{x\alpha^H}_m}{\longrightarrow} &f(x) \in R^+
$$



### 四、范数与谱估计

==定义1==：设$A \in P^{n \times n}$，记$\lambda(A) = \{\lambda | Ax = \lambda x, x \neq 0\}$为矩阵$A$的谱；记$r(A) = \max_i |\lambda_i|,\lambda_i \in \lambda(A)$，称为矩阵$A$的谱半径。

==定理1==：如果$\norm{\cdot}_m: C^{n \times n} \to R^+$是一相容的矩阵范数，则对任一$A \in C^{n \times n}$，有$|\lambda_i| \le \norm{A}_m$（其中$\lambda_i$是矩阵$A$的特征值）。

证：$Ax = \lambda_i x$，两边同时取范数，$|\lambda_i|\norm{x}_m = \norm{\lambda_i x}_m = \norm{Ax} \le \norm{A}_m \cdot \norm{x}_m \Longrightarrow |\lambda_i| \le \norm{A}_m$。

由上述定理可知，如果$\norm{\cdot}_m: C^{n \times n} \to R^+$是一相容的矩阵范数，则对任一$A \in C^{n \times n}$，有$r(A) \le \norm{A}_m$。



例1：$A = \left[\begin{array}{cc}0 &1 \\ 1 &1\end{array}\right] \Longrightarrow \norm{A}_{m_\infty} = 1$，$|\lambda E - A| = \left[\begin{array}{cc}\lambda &-1 \\ -1 &\lambda-1\end{array}\right] = \lambda(\lambda-1) - 1 = \lambda^2-\lambda - 1 \triangleq 0$，解得$\lambda_{1, 2} = \frac{1 \pm \sqrt{5}}{2}$，从而$r(A) = \frac{1+\sqrt{5}}{2} > 1.6 > 1 = \norm{A}_{m_\infty}$。



例2：设$A \in P^{n \times n}$，存在可逆矩阵$P$，使得$P^{-1}AP = J$，其中：
$$
J = \left[\begin{array}{c}\lambda_1 &k_1 \\ \ &\lambda_2 &k_2 \\ \ &\ &\ddots &\ddots \\ \ &\ &\ &\lambda_{n-1} &k_{n-1} \\ \ &\ &\ &\ &\lambda_n\end{array}\right], (k_i \in \{0, 1\})
$$
$\forall_\epsilon > 0$，令$Q = \operatorname{diag}(1, \epsilon, \epsilon^2, \cdots, \epsilon^{n-1})$，则：
$$
Q^{-1}JQ = Q^{-1}P^{-1}APQ = D^{-1}AD \\
= \left[\begin{array}{c}1 \\ \ &\frac{1}{\epsilon} \\ \ &\ &\ddots \\ \ &\ &\ &\frac{1}{\epsilon^{n-2}} \\ \ &\ &\ &\ &\frac{1}{\epsilon^{n-1}}\end{array}\right] 
\left[\begin{array}{c}\lambda_1 &k_1 \\ \ &\lambda_2 &k_2 \\ \ &\ &\ddots &\ddots \\ \ &\ &\ &\lambda_{n-1} &k_{n-1} \\ \ &\ &\ &\ &\lambda_n\end{array}\right]
\left[\begin{array}{c}1 \\ \ &\epsilon \\ \ &\ &\ddots \\ \ &\ &\ &\epsilon^{n-2} \\ \ &\ &\ &\ &\epsilon^{n-1}\end{array}\right] \\
= \left[\begin{array}{c}\lambda_1 &k_1\epsilon \\ \ &\lambda_2 &k_2\epsilon \\ \ &\ &\ddots &\ddots \\ \ &\ &\ &\lambda_{n-1} &k_{n-1}\epsilon \\ \ &\ &\ &\ &\lambda_n\end{array}\right]
$$
$\norm{A}_m \triangleq \norm{D^{-1}AD}_\infty = \max\{|\lambda_i| + k_i\epsilon\} \le \max_i |\lambda_i| + \epsilon = r(A) + \epsilon$（极大行和）。

$\forall_{A, B} \in P^{n \times n}$，$\norm{AB}_m = \norm{D^{-1}ABD}_\infty = \norm{(D^{-1}AD)(D^{-1}BD)}_\infty \le \norm{D^{-1}AD} \cdot \norm{D^{-1}BD} = \norm{A}_m \cdot \norm{B}_m$，从而$\norm{\cdot}_m$是自相容范数。



$\forall_\epsilon > 0$，对于与$\epsilon$相关的自相容矩阵范数$\norm{A}_m$，

一方面根据定理1，有$r(A) \le \norm{A}_m$，从而$r(A) - \epsilon \le \norm{A}_m$；

另一方面$\norm{A}_m \le r(A) + \epsilon$。

综上，$r(A) - \epsilon \le \norm{A}_m \le r(A) + \epsilon$，从而$[r(A)]^k - \epsilon \le \norm{A^k}_m \le [r(A)]^k + \epsilon$（矩阵$A^k$的特征值为矩阵$A$的特征值的$k$次方）。



### 五、算子范数的计算

（1）从属于向量范数$\norm{x}_1$的算子范数$\norm{A}_1 = \max_j(\sum_{i=1}^n |a_{ij}|)$，称为极大列和范数。

证：

**课本的思路（存在上界且可达）**：$\forall_{x \neq 0}, \frac{\norm{Ax}_1}{\norm{x}_1} \le \max_j (\sum_{i=1}^n |a_{ij}|); \exist_{x_0 \neq 0}, \frac{\norm{Ax_0}}{\norm{x_0}} = \max_j(\sum_{i=1}^n |a_{ij}|)$。

证（这里换个思路证明）：
$$
Ax = \left[\begin{array}{cccc}
a_{11} &a_{12} &\cdots &a_{1n} \\
a_{21} &a_{22} &\cdots &a_{2n} \\
\vdots &\cdots &\ddots &\vdots \\
a_{n1} &a_{n2} &\cdots &a_{nn}
\end{array}\right]
\left[\begin{array}{c}
x_1 \\ x_2 \\ \vdots \\ x_n
\end{array}\right]
= \left[\begin{array}{c}
\sum_{j=1}^n a_{1j}x_j \\ \sum_{j=1}^n a_{2j}x_j \\ \vdots \\ \sum_{j=1}^n a_{nj}x_j
\end{array}\right]
$$

一方面：
$$
\norm{Ax}_1 = \sum_{i=1}^n |\sum_{j=1}^n a_{ij}x_j| \le \sum_{i=1}^n \sum_{j=1}^n |a_{ij}| \cdot |x_j| = \sum_{j=1}^n \sum_{i=1}^n |a_{ij}| \cdot |x_j| = \sum_{j=1}^n |x_j| \cdot (\sum_{i=1}^n |a_{ij}|) \\
\le \sum_{j=1}^n |x_j| \cdot [\max_j(\sum_{i=1}^n |a_{ij}|)] = \max_j(\sum_{i=1}^n |a_{ij}|) \cdot \sum_{j=1}^n |x_j| = \max_j(\sum_{i=1}^n |a_{ij}|) \cdot \norm{x}_1 \\
\Longrightarrow \frac{\norm{Ax}_1}{\norm{x}_1} \le \max_j(\sum_{i=1}^n |a_{ij}|) \\
\Longrightarrow \norm{A}_1 = \max_{x \neq 0}\frac{\norm{Ax}_1}{\norm{x}_1} \le \max_j(\sum_{i=1}^n |a_{ij}|)
$$

另一方面：令$A = [\alpha_1, \alpha_2, \cdots, \alpha_s, \cdots, \alpha_n]$，且$\sum_{i=1}^n |a_{is}| = \max_j(\sum_{i=1}^n |a_{ij}|), (i \le s \le n) \Longrightarrow \norm{\alpha_s}_1 = \max_j(\sum_{i=1}^n |a_{ij}|)$。

取$e_s = [0, \cdots, 0, 1_{[s]}, 0, \cdots, 0]^T \Longrightarrow \norm{e_s}_1 = 1 \Longrightarrow \norm{Ae_s}_1 = \norm{\alpha_s}_1$，从而$\norm{A}_1 = \max_{x \neq 0}\frac{\norm{Ax}_1}{\norm{x}_1} \ge \frac{\norm{Ae_s}_1}{\norm{e_s}_1} = \norm{\alpha_s}_1 = \max_j(\sum_{i=1}^n |a_{ij}|)$，综上有$\norm{A}_1 = \max_{x \neq 0}\frac{\norm{Ax}_1}{\norm{x}_1} = \max_j(\sum_{i=1}^n |a_{ij}|)$。



（2）从属于$\norm{x}_\infty$的算子范数$\norm{A}_\infty = \max_i(\sum_{j=1}^n |a_{ij}|)$，称为极大行和范数。

证：
$$
\norm{Ax}_\infty = \max_i\{|\sum_{j=1}^n a_{ij}x_j|\} \le \max_i\{\sum_{j=1}^n |a_{ij}| \cdot |x_j|\} \\
\le \max_i\{\sum_{j=1}^n |a_{ij}| \cdot \max_j\{|x_j|\}\} = \max_j\{|x_j|\} \cdot \max_i\{\sum_{j=1}^n |a_{ij}|\} \\
= \max_i\{\sum_{j=1}^n |a_{ij}|\} \cdot \norm{x}_\infty \\
\Longrightarrow \frac{\norm{Ax}_\infty}{\norm{x}_\infty} \le \max_i\{\sum_{j=1}^n |a_{ij}|\} \\
\Longrightarrow \norm{A}_\infty = \max_{x \neq 0}\frac{\norm{Ax}_\infty}{\norm{x}_\infty} \le \max_i\{\sum_{j=1}^n |a_{ij}|\}
$$
令$\mu = \sum_{j=1}^n |a_{sj}| = \max_i(\sum_{j=1}^n |a_{ij}|), 1 \le s \le n$，记$a_{sj} = |a_{sj}|e^{i \theta_j^{(s)}}, (j=1,2,\cdots,n) \Longrightarrow z = [e^{-i\theta_1^{(s)}}, e^{-i\theta_2^{(s)}}, \cdots, e^{-i\theta_n^{(s)}}]^T \Longrightarrow \norm{z}_\infty = 1$。

==证法一==：

因为上面已经得到了$\frac{\norm{Ax}_\infty}{\norm{x}_\infty} \le \max_i\{\sum_{j=1}^n |a_{ij}|\}$，即函数$f(x) = \frac{\norm{Ax}_\infty}{\norm{x}_\infty}$有上界$\max_i\{\sum_{j=1}^n |a_{ij}|\}$，因而只需再证明存在一点$\xi,(\norm{\xi}_\infty = 1)$，使得$\norm{A\xi}_\infty = \max_i\{\sum_{j=1}^n |a_{ij}|\}$即可（这里使用算子范数的第二种表达形式）。

令$\xi = z$，则$\norm{A\xi}_\infty = \norm{Az}_\infty$，根据复数乘法的运算法则（即两个复数的乘积的模长等于两个复数模长的乘积，两个复数的乘积的辐角等于两个复数的辐角的和），向量$Az$的第$i$个分量$\gamma_i = \sum_{j=1}^n a_{ij}e^{-i\theta_j^{(s)}}$，因为$|e^{-i\theta_j^{(s)}}| = 1$，$a_{ij}e^{-i\theta_j^{(s)}}$的模长与$a_{ij}$的模长相等，相当于把$a_{ij}$按照角度$\theta_j^{(s)}$在复平面上进行旋转。所以$|\gamma_i| = |\sum_{j=1}^n a_{ij}e^{-i\theta_j^{(s)}}| \le \sum_{j=1}^n |a_{ij} e^{-i\theta_j^{(s)}}| = \sum_{j=1}^n |a_{ij}|$，即向量$Az$的第$i$个分量$\gamma_i$的模小于或等于矩阵$A$第$i$行元素取模之后的和。特殊地，当$i = s$时，由于旋转角度$\theta_j^{(s)}$取自矩阵$A$第$s$行元素的辐角，所以$a_{sj}$按照角度$\theta_j^{(s)}$在复平面上进行旋转后正好落在了实轴上，即$a_{sj}e^{-i\theta_j^{(s)}}$是实数，从而$|\gamma_s| = |\sum_{j=1}^n a_{sj}e^{-i\theta_j^{(s)}}| = \sum_{j=1}^n |a_{sj}| = \mu$，由于$\mu$是最大行和，有$|\gamma_i| \le \sum_{j=1}^n |a_{ij}| \le \mu$，从而$\norm{Az}_\infty = \max_i \{|\gamma_i|\} = \mu = \max_i\{\sum_{j=1}^n |a_{ij}|\}$，即函数$f(x) = \frac{\norm{Ax}_\infty}{\norm{x}_\infty}$在点$z$处达到上界值$\max_i\{\sum_{j=1}^n |a_{ij}|\}$，因此函数$f(x) = \frac{\norm{Ax}_\infty}{\norm{x}_\infty}$的最大值为$\max_i\{\sum_{j=1}^n |a_{ij}|\}$，即$\norm{A}_\infty = \max_{x \neq 0}\frac{\norm{Ax}_\infty}{\norm{x}_\infty} = \max_i\{\sum_{j=1}^n |a_{sj}|\}$。

==证法二==：

上面已经得到$\norm{A}_\infty = \max_{x \neq 0}\frac{\norm{Ax}_\infty}{\norm{x}_\infty} \le \max_i\{\sum_{j=1}^n |a_{ij}|\}$，现只需再证$\norm{A}_\infty \ge \max_i\{\sum_{j=1}^n |a_{ij}|\}$即可得到$\norm{A}_\infty  = \max_i\{\sum_{j=1}^n |a_{ij}|\}$。

先求$\norm{Az}_\infty$，根据定义，$\norm{Az}_\infty$是向量$Az$分量模的最大值，因此$\norm{Az}_\infty \ge |\sum_{j=1}^n a_{ij}e^{-i\theta_j^{(s)}}| \Longrightarrow \norm{Az}_\infty \ge |\sum_{j=1}^n a_{sj}e^{-i\theta_j^{(s)}}| = \sum_{j=1}^n |a_{sj}| = \mu = \mu \norm{z}_\infty$，所以$\frac{\norm{Az}_\infty}{\norm{z}_\infty} \ge \mu$，从而$\norm{A}_\infty = \max_{x \neq 0}\frac{\norm{Ax}_\infty}{\norm{x}_\infty} \ge \frac{\norm{Az}_\infty}{\norm{z}_\infty} = \mu = \max_i\{\sum_{j=1}^n |a_{ij}|\}$，证毕！



（3）设$A \in P^{n \times n}$，则从属于$\norm{x}_2$的算子范数（又称为谱范数）$\norm{A}_2 = \sqrt{r(A^HA)}$。

证：$f(x) = x^H(A^HA)x = (Ax)^H(Ax) \ge 0 \Longrightarrow \lambda_1 \ge \lambda_2 \ge \cdots \ge \lambda_n \ge 0, A^HA \xi_i = \lambda_i\xi_i, (i=1,2,\cdots,n)$，（其中$\xi_i^H \xi_j = \left\{\begin{array}{cc}1, &i=j \\ 0, &i \neq j\end{array}\right.$）。设$\forall_u \in P^n$且$\norm{u} = 1$（$\Longleftrightarrow \norm{u}_2^2 = u^Hu = 1$）。令$u = a_1\xi_1 + a_2\xi_2 + \cdots + a_n\xi_n$，则有$u^H = \overline{a_1}\xi_1^H + \overline{a_2}\xi_2^H + \cdots + \overline{a_n}\xi_n^H$，从而$1 = \norm{u}_2^2 = u^Hu = |a_1|^2 + |a_2|^2 + \cdots + |a_n|^2$，$A^HAu = a_1\lambda_1\xi_1 + a_2\lambda_2\xi_2 + \cdots + a_n\lambda_n\xi_n$$\Longrightarrow$$\norm{Au}_2^2 = (Au)^H(Au) = u^HA^HAu = \lambda_1|a_1|^2+\lambda_2|a_2|^2+\cdots+\lambda_n|a_n|^2 \le \lambda_1(|a_1|^2+|a_2|^2+\cdots+|a_n|^2) = \lambda_1$，即$\norm{Au}_2 \le \sqrt{\lambda_1}$。即$\forall_u, \norm{Au}_2 \le \sqrt{\lambda_1}$（上界存在）。

又$\norm{A\xi_1}_2^2 = \xi_1^H A^H A \xi_1 = \xi_1^H \lambda_1 \xi_1 = \lambda_1$，即$\norm{A\xi_1}_2 = \sqrt{\lambda_1}$（上界可达）。

所以$\norm{A}_2 = \max_{\norm{u}_2 = 1}\norm{Au}_2 = \sqrt{\lambda_1} = \sqrt{r(A^HA)}$。



若$A^H = A$，则$\norm{A}_2 = \sqrt{r(A^HA)} = \sqrt{r(A^2)} = \sqrt{r^2(A)} = r(A)$；

若$A^H = A, B^H = B, AB = BA$，则$r(AB) \le r(A) \cdot r(B)$（意义：从两个已知矩阵的谱半径估计它们乘积的谱半径）。





### 六、谱范数的性质

（1）$\norm{A}_2 = \norm{A^H}_2 = \norm{A^T}_2 = \norm{\overline{A}}_2$。

证：先证$\norm{A}_2 = \norm{A^H}_2$。

$\norm{A}_2 = \sqrt{r(A^HA)}$，$\norm{A^H}_2 = \sqrt{r[(A^H)^H A^H]} = \sqrt{r(AA^H)}$，要证明$\norm{A}_2 = \norm{A^H}_2$，即证$\sqrt{r(A^HA)} = \sqrt{r(AA^H)} \Longleftrightarrow r(A^HA) = r(AA^H)$，下面证明$\lambda(A^HA) = \lambda(AA^H)$。

若$0 \in \lambda(A^HA)$，则$\det(A^HA) = 0 \Longleftrightarrow \det(A^H) \cdot \det(A) = \det(A) \cdot \det(A^H) = \det(AA^H) = 0$，从而$0 \in \lambda(AA^H)$；

若$0 \neq \lambda \in \lambda(A^HA)$，则$A^HA x = \lambda x, (x \neq 0)$，等式两边同时左乘$A$得$AA^HAx = \lambda Ax$，令$y = Ax, y \neq 0$（若$y = Ax = 0$，则$A^HAx = \lambda x \Longrightarrow A^H \cdot 0 = \lambda x \Longrightarrow x = 0$，矛盾），得$AA^H y = \lambda y, (y \neq 0)$，即$\lambda$是矩阵$AA^H$的特征值，从而$\lambda(A^HA) \subset \lambda(AA^H)$，

同理可证：$AA^H$的特征值也是$A^HA$的特征值，即$\lambda(AA^H) \subset \lambda(A^HA)$。

从而$\lambda(A^HA) = \lambda(AA^H)$，证毕！



再证$\norm{A^H}_2 = \norm{A^T}_2$。

$\norm{A^H}_2 = \sqrt{r(AA^H)} = \sqrt{r[(AA^H)^T]} = \sqrt{r[(A^H)^T A^T]} = \sqrt{r[(A^T)^H A^T]} = \norm{A^T}_2$（用到了方阵的转置与原方阵具有相同的特征值。）



最后证$\norm{A^H}_2 = \norm{\overline{A}}_2$。

由$\norm{A}_2 = \norm{A^H}_2$，可得$\norm{A^T}_2 = \norm{(A^T)^H}_2 = \norm{\overline{A}}_2$，证毕！



（2）对于任何$n$阶酉矩阵$U$和$V$，都有$\norm{UA}_2 = \norm{AV}_2 = \norm{UAV}_2 = \norm{A}_2$（酉不变性）。

证：$\norm{UA}_2^2 = r[(UA)^H (UA)] = r(A^H U^HU A) = r(A^HA) = \norm{A}_2^2$，$\norm{AV}_2^2 = r[(AV)^H (AV)] = r(V^HA^H  AV) = r(V^HA^HU^H UAV) = r[(UAV)^H (UAV)] = \norm{UAV}_2^2$，

由$V^HV = E$，得$V^{-1} = V^H$，从而$V^{-1}A^HAV = V^HA^HAV$与$A^HA$相似，从而$r(V^HA^HAV) = r(A^HA)$。

$\norm{AV}_2^2 = r[(AV)^H(AV)] = r(V^HA^HAV) = r(A^HA) = \norm{A}_2^2$。

将等式两边开方即得结论。



==定理1==：设$A \in C^{n \times n}$，则：

（1）$\norm{A}_2 = \max_{\norm{x}_2 = 1, \norm{y}_2 = 1}|y^HAx|$（仅有理论分析和推导的意义，不用来计算）；

（2）$\norm{A}_2^2 \le \norm{A}_1 \cdot \norm{A}_\infty$。



证：

（1）（有界且可达）：$\forall_{x, y}(\norm{x}_2 = \norm{y}_2 = 1)$，由柯西不等式和算子-2范数的自相容性，$|y^HAx| \le \norm{y}_2 \cdot \norm{Ax}_2 \le \norm{y}_2 \cdot \norm{A}_2 \cdot \norm{x}_2 = \norm{A}_2$，即$\forall_{x, y}(\norm{x}_2 = \norm{y}_2 = 1), |y^HAx| \le \norm{A}_2$（存在上界$\norm{A}_2$）；

$\norm{A}_2 = \max_{\norm{x}_2 = 1}\norm{Ax}_2 \Longrightarrow \exist_{x_0 \neq 0}, s.t. \ \norm{A}_2 = \norm{Ax_0}_2 > 0$，再令$y_0 = \frac{Ax_0}{\norm{Ax_0}_2}$，则$|y^HAx_0| = |\frac{(Ax_0)^H}{\norm{Ax_0}_2} Ax_0| = \norm{Ax_0}_2 = \norm{A}_2$（上界可达）。

从而$\norm{A}_2 = \max_{\norm{x}_2 = 1, \norm{y}_2 = 1}|y^HAx|$。



（2）$\norm{A}_2^2 = r(A^HA) \le \norm{A^HA}_1 \le \norm{A^H}_1 \cdot \norm{A}_1 =  \norm{\overline{A}}_\infty \cdot \norm{A}_1 = \norm{A}_1 \cdot \norm{A}_\infty$。





### 七、范数与扰动分析

（1）数值计算中有两类误差影响计算结果的精度：

1. 计算方法引起的截断误差；
2. 计算环境引起的舍入误差（如计算机字长限制等）。

这两类误差可归结为原始数据的扰动对解的影响。



（2）线性方程组求解和矩阵特征值求解的扰动：

1. $Ax = b \Longrightarrow x = A^{-1}b$
   $$
   \left[\begin{array}{cc}
   1 &0.99 \\
   0.99 &0.98
   \end{array}\right] 
   \left[\begin{array}{c}
   x_1 \\ x_2
   \end{array}\right] 
   = \left[\begin{array}{c}
   1 \\ 1
   \end{array}\right] 
   \Longrightarrow
   \left[\begin{array}{c}
   x_1 \\ x_2
   \end{array}\right] 
   = 
   \left[\begin{array}{c}
   100 \\ -100
   \end{array}\right]
   $$

   $$
   \left[\begin{array}{cc}
   1 &0.99 \\
   0.99 &0.99
   \end{array}\right] 
   \left[\begin{array}{c}
   \tilde{x_1} \\ \tilde{x_2}
   \end{array}\right] 
   = \left[\begin{array}{c}
   1 \\ 1.001
   \end{array}\right] 
   \Longrightarrow
   \left[\begin{array}{c}
   \tilde{x_1} \\ \tilde{x_2}
   \end{array}\right] 
   = 
   \left[\begin{array}{c}
   -0.1 \\ \frac{10}{9}
   \end{array}\right]
   $$

   

2. $Ax = \lambda x \Longrightarrow \lambda = ?$
   $$
   A = \left[\begin{array}{cccc}
   0 &1 &0 &0 \\
   0 &0 &1 &0 \\
   0 &0 &0 &1 \\
   0 &0 &0 &0
   \end{array}\right] 
   \Longrightarrow 
   \lambda(A) = \{0, 0, 0, 0\}
   $$

   $$
   A + \delta A = \left[\begin{array}{cccc}
   0 &1 &0 &0 \\
   0 &0 &1 &0 \\
   0 &0 &0 &1 \\
   10^{-4} &0 &0 &0
   \end{array}\right] 
   \Longrightarrow 
   \lambda(A + \delta A) = \{\pm 0.1, \pm 0.1i\}
   $$

   

（3）病态的概念

1. 稳定性问题：原始数据的扰动引起解的变化有多大。

2. $Ax = b \Longrightarrow x = A^{-1}b$，若系数矩阵$A$或者常数项$b$的微小变化，引起$Ax = b$解的巨大变化，则称方程组为病态方程组，其系数矩阵$A$就叫做对于解方程组（或求逆）的病态矩阵。反之，方程组就称为良态方程组，$A$称为良态矩阵。

3. $Ax = \lambda x \Longrightarrow \lambda = ?$，若矩阵$A$的微小变化引起特征值的巨大变化，则称矩阵$A$对求特征值来说是病态矩阵。

4. 病态矩阵的界定：谈到“病态矩阵”概念时，必须明确它是对什么而言，因对于方程组求解（求逆）来说是病态的矩阵，对于求特征值来说并不一定是病态的，反之亦然。所以不能笼统地说某个矩阵是“病态”的。

5. 病态属性：“病态”是矩阵本身的特性，与所用的计算工具与计算方法无关。但是，实际计算中“病态”的程度确通过计算工具等表现出来。如计算机字长愈长，“病态”现象在某种程度上就会相对地减轻。

   

（4）病态的分析工具（条件数）：$\operatorname{Cond}(A) = \norm{A^{-1}}_p \cdot \norm{A}_p$，$\norm{\cdot}_p$是相容矩阵范数。

$\norm{A^{-1}A}_p = \norm{E}_p \le \norm{A^{-1}}_p \cdot \norm{A}_p$，若$\norm{\cdot}_p$是算子范数，则$\norm{E}_p = 1$，此时条件数$\operatorname{Cond}(A) \ge 1$。

（5）扰动分析

==应用1==：矩阵逆的摄动

1. 矩阵$A$可逆，$A$与其摄动矩阵$\delta A$满足什么条件时，$A + \delta A$可逆？
2. 当$A + \delta A$可逆时，$A^{-1}$与$(A+\delta A)^{-1}$的近似程度如何估计？

==定理1==：$A \in C^{n \times n}$，$\norm{A}_a$是从属于向量范数$\norm{x}_a$的矩阵范数，如果$\norm{A}_a < 1$，则$E \pm A$可逆，且$\norm{(E \pm A)^{-1}}_a \le \frac{1}{1-\norm{A}_a}$。

证：先证$E \pm A$可逆。

设$\lambda$是矩阵$A$的特征值，$x \neq 0$是矩阵$A$的属于特征值$\lambda$的特征向量，则$Ax = \lambda x$。

$(E \pm A)x = x \pm Ax = x \pm \lambda x = (1 \pm \lambda)x$，从而$(1 \pm \lambda)$是矩阵$(E \pm A)$的特征值。

因为$\norm{A}_a < 1$，则$\forall_{\lambda_i} \in \lambda(A), |\lambda_i| \le \norm{A}_a < 1 \Longrightarrow \lambda_i \neq 1$。从而$0 \neq 1 \pm \lambda \in \lambda(E \pm A) \Longrightarrow (E \pm A)$可逆。

或者用反证法：

反设$E \pm A$不可逆，则方程$(E \pm A)x = 0$有非零解，$x = \mp Ax$，等式两边同时取范数，$\norm{x}_a = \norm{Ax}_a \le \norm{A}_a \cdot \norm{x}_a$，由$x \neq 0 \Longrightarrow \norm{x}_a > 0$，不等式两边同时除以$\norm{x}_a$得$1 \le \norm{A}_a$，出现矛盾。

再证$\norm{(E \pm A)^{-1}}_a \le \frac{1}{1-\norm{A}_a}$。

$(E \pm A)^{-1}(E \pm A) = E \Longrightarrow (E - A)^{-1} - (E - A)^{-1}A = E \Longrightarrow (E - A)^{-1} = (E-A)^{-1}A + E$，等式两边同时取范数得$\norm{(E-A)^{-1}}_a = \norm{(E-A)^{-1}A + E}_a \le \norm{(E-A)^{-1}A}_a + \norm{E}_a \le \norm{(E-A)^{-1}}_a\cdot\norm{A}_a + 1$，从而$(1-\norm{A}_a)\norm{(E-A)^{-1}}_a \le 1 \Longrightarrow \norm{(E-A)^{-1}}_a \le \frac{1}{1-\norm{A}_a}$。



==定理2==：$A$可逆，$\delta A$为扰动矩阵，$\norm{A^{-1}\delta A}_a < 1$，则：

1. $A + \delta A$可逆；
2. $\frac{\norm{A^{-1}-(A+\delta A)^{-1}}_a}{\norm{A^{-1}}_a} \le \frac{\norm{A^{-1}\delta A}_a}{1 - \norm{A^{-1}\delta A}_a}$；
3. $\frac{\norm{A^{-1} - (A+\delta A)^{-1}}_a}{\norm{A^{-1}}_a} \le \frac{k(A)\frac{\norm{\delta A}_a}{\norm{A}_a}}{1 - k(A)\frac{\norm{\delta A}_a}{\norm{A}_a}}$，其中$k(A) = \norm{A^{-1}}_a \cdot \norm{A}_a$。

证：

1. 若$\norm{A^{-1}\delta A}_a < 1$，根据定理1的结论，有$E + A^{-1}\delta A$可逆，即$A^{-1}A + A^{-1}\delta A = A^{-1}(A+\delta A)$可逆，从而$(A + \delta A)$可逆。

2. 
   $$
   (A + \delta A)^{-1} - A^{-1} = [A(E + A^{-1}\delta A)]^{-1} - A^{-1} \\
   = (E + A^{-1}\delta A)^{-1}A^{-1} - A^{-1} = [(E + A^{-1}\delta A)^{-1} - E]A^{-1} \\
   = [(E + A^{-1}\delta A)^{-1} - (E + A^{-1}\delta A)^{-1} \cdot (E + A^{-1}\delta A)]A^{-1} \\
   = (E + A^{-1}\delta A)^{-1}[E - (E + A^{-1}\delta A)]A^{-1} \\
   = (E + A^{-1}\delta A)^{-1}(-A^{-1}\delta A)A^{-1} \Longrightarrow \\
   \norm{(A + \delta A)^{-1} - A^{-1}}_a = \norm{(E + A^{-1}\delta A)^{-1}(-A^{-1}\delta A)A^{-1}}_a \\
   \le \norm{(E + A^{-1}\delta A)^{-1}}_a \cdot \norm{(-A^{-1}\delta A)}_a \cdot \norm{A^{-1}}_a \\
   \le \frac{ \norm{(-A^{-1}\delta A)}_a \cdot \norm{A^{-1}}_a}{1 - \norm{A^{-1}\delta A}_a} \\
   \Longrightarrow \frac{\norm{(A + \delta A)^{-1} - A^{-1}}_a}{\norm{A^{-1}}_a} \le \frac{ \norm{A^{-1}\delta A}_a}{1 - \norm{A^{-1}\delta A}_a}
   $$

3. 令$x = \norm{A^{-1}\delta A}_a < 1$，则$\frac{\norm{(A + \delta A)^{-1} - A^{-1}}_a}{\norm{A^{-1}}_a} \le \frac{ \norm{A^{-1}\delta A}_a}{1 - \norm{A^{-1}\delta A}_a} = \frac{x}{1-x}$，$f(x) \triangleq \frac{x}{1-x}, (x \ge 0)$，$f^\prime(x) = (\frac{x}{1-x})^\prime = (\frac{1}{1-x} - 1)^\prime = \frac{1}{(1-x)^2} > 0$，所以$f(x)$是单调增函数，取$x_1 = \norm{A^{-1}\delta A}_a \le \norm{A^{-1}}_a \cdot \norm{\delta A}_a = x_2$，有$\frac{ \norm{A^{-1}\delta A}_a}{1 - \norm{A^{-1}\delta A}_a} = f(x_1) \le f(x_2) = \frac{\norm{A^{-1}}_a \cdot \norm{\delta A}_a}{1-\norm{A^{-1}}_a \cdot \norm{\delta A}_a} = \frac{\norm{A^{-1}}_a \cdot \norm{A}_a \cdot \frac{\norm{\delta A}_a}{\norm{A}_a}}{1- \norm{A^{-1}}_a \cdot \norm{A}_a \cdot \frac{\norm{\delta A}_a}{\norm{A}_a}} = \frac{k(A) \cdot \frac{\norm{\delta A}_a}{\norm{A}_a}}{1- k(A) \cdot \frac{\norm{\delta A}_a}{\norm{A}_a}}$。



令$b = \frac{\norm{\delta A}_a}{\norm{A}_a} > 0$，则$\frac{k(A)\frac{\norm{\delta A}_a}{\norm{A}_a}}{1 - k(A)\frac{\norm{\delta A}_a}{\norm{A}_a}} = \frac{bx}{1-bx}$，$g(x) \triangleq \frac{bx}{1-bx}$。$g^\prime(x) = (\frac{bx}{1-bx})^\prime = (\frac{1}{1-bx} - 1)^\prime = \frac{b}{(1-bx)^2} > 0$，从而$g(x)$是单调增函数。当$b = \frac{\norm{\delta A}_a}{\norm{A}_a} > 0$（相对扰动误差）给定时，$x = k(A)$越大，$g(x) = \frac{k(A)\frac{\norm{\delta A}_a}{\norm{A}_a}}{1 - k(A)\frac{\norm{\delta A}_a}{\norm{A}_a}}$也越大，即$\frac{\norm{(A + \delta A)^{-1} - A^{-1}}_a}{\norm{A^{-1}}_a}$的上界越大，从而$A^{-1}$与$(A+\delta A)^{-1}$的差距也可能会更大。

   

例1：设$A = \left[\begin{array}{cc}2 &6 \\ 2 &6.00001\end{array}\right], \delta A = \left[\begin{array}{cc}0 &0 \\ 0 &-0.00002\end{array}\right]$，计算可得$A^{-1} = \left[\begin{array}{cc}300000.5 &-300000 \\ -100000 &100000\end{array}\right], (A + \delta A)^{-1} = \left[\begin{array}{cc}-299999.5 &-300000 \\ 100000 &-100000\end{array}\right]$，$k(A) = \norm{A}_2 \cdot \norm{A^{-1}}_2 \approx 8.9443 \times 123.56 \approx 1105$。



例2：Hilbert Matrix: $H = (h_{ij}) \in R^{n \times n}, h_{ij} = \frac{1}{i+j-1}$。
$$
H = \left[\begin{array}{cccc}
1 &\frac{1}{2} &\cdots &\frac{1}{n} \\
\frac{1}{2} &\frac{1}{3} &\cdots &\frac{1}{n+1} \\
\vdots &\cdots &\ddots &\vdots \\
\frac{1}{n} &\frac{1}{n+1} &\cdots &\frac{1}{n+(n-1)}
\end{array}\right]
$$
$k(A) = \norm{A}_2 \cdot \norm{A^{-1}}_2 \approx 4.7661e+005, (n=5)$。



==应用2==：线性方程组的摄动

==定理3==：在方程组$Ax = b$中，$A$固定且可逆，令$b \neq 0$且有小的摄动$\delta b$，则解方程组$A(x_0 + \delta x) = b + \delta b, (Ax_0 = b)$，得$\frac{\norm{(x_0+\delta x) - x_0}_a}{\norm{x_0}_a} = \frac{\norm{\delta x}_a}{\norm{x_0}_a} \le k(A)\frac{\norm{\delta b}_a}{\norm{b}_b}$。



==定理4==：在方程组$Ax = b$中，$b$固定且$b \neq 0$，可逆矩阵$A$有很小的摄动$\delta A$，且$\norm{A^{-1}}_a \cdot \norm{\delta A}_a < 1$，解方程组$(A+\delta A)(x_0 + \delta x) = b, (Ax_0 = b)$，得$\frac{\norm{(x_0+\delta x) - x_0}_a}{\norm{x_0}_a} = \frac{\norm{\delta x}_a}{\norm{x_0}_a} \le \frac{k(A) \cdot \frac{\norm{\delta A}_a}{\norm{A}_a}}{1- k(A) \cdot \frac{\norm{\delta A}_a}{\norm{A}_a}}$。



==定理5==：在方程组$Ax = b$中，$b \neq 0$有小的摄动$\delta b$，可逆矩阵$A$有小的摄动$\delta A$，且$\norm{A^{-1}}_a \cdot \norm{\delta A}_a < 1$，解方程组$(A+\delta A)(x_0 + \delta x) = b + \delta b, (Ax_0 = b)$，得$\frac{\norm{(x_0+\delta x) - x_0}_a}{\norm{x_0}_a} = \frac{\norm{\delta x}_a}{\norm{x_0}_a} \le \frac{k(A)}{r(A)}(\frac{\norm{\delta A}_a}{\norm{A}_a} + \frac{\norm{\delta b}_a}{\norm{b}_a})$，其中$k(A) = \norm{A^{-1}}_a \cdot \norm{A}_a, r(A) = 1- k(A)\frac{\norm{\delta A}_a}{\norm{A}_a} > 0$。



例3：方程组$Ax = b$，$A = \left[\begin{array}{cc}2 &6 \\ 2 &6.00001\end{array}\right], b = \left[\begin{array}{c}8 \\ 8.00001\end{array}\right]$，摄动矩阵和向量为$A + \delta A = \left[\begin{array}{cc}2 &6 \\ 2 &5.99999\end{array}\right], b + \delta b = \left[\begin{array}{c}8 \\ 8.00002\end{array}\right]$，方程组$Ax = b$的准确解为$x_0 = \left[\begin{array}{c}1 \\ 1\end{array}\right]$，方程组$(A+\delta A)x = b + \delta b$的解$\tilde{x} = \left[\begin{array}{c}10 \\ -2\end{array}\right]$。



==方程组的预处理==：

例4：方程组$Ax = b \Longrightarrow \left[\begin{array}{cc}1 &10^5 \\ 1 &1\end{array}\right] \left[\begin{array}{c}x_1 \\ x_2\end{array}\right] = \left[\begin{array}{c}10^5 \\ 2\end{array}\right]$，$A^{-1} = \frac{1}{10^5-1}\left[\begin{array}{cc}-1 &10^5 \\ 1 &-1\end{array}\right]$，$k_\infty(A) = \norm{A}_\infty \cdot \norm{A^{-1}}_\infty = (1+10^5) \cdot \frac{1}{10^5 - 1}(1 + 10^5) = \frac{(1+10^5)^2}{(10^5-1)} \approx 10^5$。

==作预处理==：

$\left[\begin{array}{cc}10^{-5} &1 \\ 1 &1\end{array}\right] \left[\begin{array}{c}x_1 \\ x_2\end{array}\right] = \left[\begin{array}{c}1 \\ 2\end{array}\right] \Longleftrightarrow Bx = \left[\begin{array}{c}1 \\ 2\end{array}\right]$，$k_\infty(B) \approx 4$。



==参考资料==：特征值的扰动分析相对难得多，对于扰动分析相关参考资料，推荐中科大的《矩阵扰动分析》。

